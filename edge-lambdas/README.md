## Product Web Lambda@Edge Lambdas

### Overview

This project contains source code for [Edge Lambda functions](https://aws.amazon.com/lambda/edge/)
that support serving of the SPA apps.

### Setup

The source code of the lambdas live in the `src` directory. Each edge lambda exposes a `handler`
method which is the entrypoint used in CF configuration.

#### Test

Tests are collocated with the source files, one test suite per edge lambda. Run tests with
`make test`.

#### Build

Each edge lambda is built using [Vercel's `ncc`](https://github.com/vercel/ncc) which takes care of
bundling and compiling. The built lambdas are placed in `dist` directory after running the build
script. Run build of all lambdas with `make`

### Config

Since Lambda@Edge functions can't use environment variables, we use config JSON files uploaded
together with the lambda file to store configuration. The config files are generated by Terraform as
part of the deployment process for each environment.

### Details

> [Lambda@Edge lambdas](https://aws.amazon.com/lambda/edge/) are used when serving assets from
> [Cloudfront](https://aws.amazon.com/cloudfront/) (CDN) distributions, and executed at edge
> locations, close to the user, for minimal latency. They are triggered in the request/response
> cycle of a CDN-backed asset at one of the four stages (viewer request, origin request, origin
> response and origin request). They are invoked with either `CloudFrontRequestEvent` or
> `CloudFrontResponseEvent` event depending on the stage the are associated with.

In this setup the app uses edge lambdas triggered on viewer request and viewer response. This means
that those lambdas will run on every request that is handled by the default behavior they are
associated with - no caching involved.

-   viewer request - this lambda is ran before the request to the origin (in our case S3 bucket) is
    sent and can modify which asset it requests from the origin. In our case:

    1. Inspect the Host header of the request and determine the branch that the user has requested.
       For example a request to `app.staging.pleo.io` is for the master branch of the app, while a
       request to `my-branch.app.staging.pleo` is a request for a feature branch (`my-branch`)
       version of the app.
    2. Fetch the cursor file (containing the current active tree hash) from the S3 origin bucket to
       figure out which HTML file to request from CDN. Note that this is a call to an external data
       source, and although the file is stored in the same bucket as the files served by this CDN
       distribution, in principle it could be any other data source (API, DynamoDB, etc.). To
       mitigate the potentially large performance penalty from doing it (since it's a non-cacheable,
       blocking request to a resource in a non-edge location) we use a long lived HTTP connection
       and cache it in global lambda scope which makes it available for consecutive invocations. For
       the whole discussion of this topic please see
       [AWS's guide to using external data in Edge Lambda](https://aws.amazon.com/blogs/networking-and-content-delivery/leveraging-external-data-in-lambdaedge).
    3. Once the tree hash is established the request object is modified to request the correct HTML
       file from the origin. Note that this request is now for an asset with a unique name, that can
       be fully cached on the CDN level (and we upload the file to S3 with
       `max-age=31536000,immutable` cache control settings). In the viewer response lambda we adjust
       the cache headers when sending the response to the browser to
       `max-age=0,no-cache,no-store,must-revalidate` so that the browser doesn't cache the
       non-unique url locally. This mitigates the latency added by the cursor file request further.

-   viewer response - this lambda modifies the response returned to the user's browser. Currently we
    use it set a few headers on the response:
    -   security-related headers like `X-Frame-Options` (we do that already today)
    -   `X-Robots-Tag` - replaces the `robots.txt` file - we only apply this in staging to avoid the
        preview deployments and main staging deployment from being indexed.
    -   `Cache-Control` - we need to modify this header to make sure HTML files are not cached by
        user's browser
